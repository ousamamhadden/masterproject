{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8761682242990654,
  "eval_steps": 250,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014602803738317757,
      "grad_norm": 1.453470230102539,
      "learning_rate": 4.97566199376947e-05,
      "loss": 1.3765,
      "step": 25
    },
    {
      "epoch": 0.029205607476635514,
      "grad_norm": 1.1255218982696533,
      "learning_rate": 4.9513239875389414e-05,
      "loss": 1.3412,
      "step": 50
    },
    {
      "epoch": 0.04380841121495327,
      "grad_norm": 1.6092039346694946,
      "learning_rate": 4.926985981308411e-05,
      "loss": 1.3306,
      "step": 75
    },
    {
      "epoch": 0.05841121495327103,
      "grad_norm": 1.085147738456726,
      "learning_rate": 4.902647975077882e-05,
      "loss": 1.3219,
      "step": 100
    },
    {
      "epoch": 0.07301401869158879,
      "grad_norm": 1.6311370134353638,
      "learning_rate": 4.8783099688473524e-05,
      "loss": 1.3352,
      "step": 125
    },
    {
      "epoch": 0.08761682242990654,
      "grad_norm": 0.695402204990387,
      "learning_rate": 4.853971962616823e-05,
      "loss": 1.3099,
      "step": 150
    },
    {
      "epoch": 0.1022196261682243,
      "grad_norm": 1.6968581676483154,
      "learning_rate": 4.829633956386293e-05,
      "loss": 1.3102,
      "step": 175
    },
    {
      "epoch": 0.11682242990654206,
      "grad_norm": 0.9237515926361084,
      "learning_rate": 4.8052959501557634e-05,
      "loss": 1.3168,
      "step": 200
    },
    {
      "epoch": 0.1314252336448598,
      "grad_norm": 1.2769345045089722,
      "learning_rate": 4.780957943925234e-05,
      "loss": 1.3098,
      "step": 225
    },
    {
      "epoch": 0.14602803738317757,
      "grad_norm": 1.3022220134735107,
      "learning_rate": 4.756619937694704e-05,
      "loss": 1.3056,
      "step": 250
    },
    {
      "epoch": 0.16063084112149534,
      "grad_norm": 1.5762336254119873,
      "learning_rate": 4.7322819314641744e-05,
      "loss": 1.3223,
      "step": 275
    },
    {
      "epoch": 0.17523364485981308,
      "grad_norm": 1.5681383609771729,
      "learning_rate": 4.707943925233645e-05,
      "loss": 1.3055,
      "step": 300
    },
    {
      "epoch": 0.18983644859813084,
      "grad_norm": 2.3322503566741943,
      "learning_rate": 4.6836059190031156e-05,
      "loss": 1.2932,
      "step": 325
    },
    {
      "epoch": 0.2044392523364486,
      "grad_norm": 1.1437208652496338,
      "learning_rate": 4.659267912772586e-05,
      "loss": 1.2893,
      "step": 350
    },
    {
      "epoch": 0.21904205607476634,
      "grad_norm": 1.6995948553085327,
      "learning_rate": 4.634929906542057e-05,
      "loss": 1.2931,
      "step": 375
    },
    {
      "epoch": 0.2336448598130841,
      "grad_norm": 1.3554176092147827,
      "learning_rate": 4.6105919003115266e-05,
      "loss": 1.2983,
      "step": 400
    },
    {
      "epoch": 0.24824766355140188,
      "grad_norm": 1.7259143590927124,
      "learning_rate": 4.586253894080997e-05,
      "loss": 1.2905,
      "step": 425
    },
    {
      "epoch": 0.2628504672897196,
      "grad_norm": 1.9354015588760376,
      "learning_rate": 4.561915887850468e-05,
      "loss": 1.2755,
      "step": 450
    },
    {
      "epoch": 0.2774532710280374,
      "grad_norm": 2.0533182621002197,
      "learning_rate": 4.5375778816199376e-05,
      "loss": 1.2834,
      "step": 475
    },
    {
      "epoch": 0.29205607476635514,
      "grad_norm": 1.8251081705093384,
      "learning_rate": 4.513239875389408e-05,
      "loss": 1.2942,
      "step": 500
    },
    {
      "epoch": 0.3066588785046729,
      "grad_norm": 2.004927635192871,
      "learning_rate": 4.488901869158879e-05,
      "loss": 1.3215,
      "step": 525
    },
    {
      "epoch": 0.3212616822429907,
      "grad_norm": 1.2310553789138794,
      "learning_rate": 4.464563862928349e-05,
      "loss": 1.2792,
      "step": 550
    },
    {
      "epoch": 0.3358644859813084,
      "grad_norm": 1.224444031715393,
      "learning_rate": 4.440225856697819e-05,
      "loss": 1.2837,
      "step": 575
    },
    {
      "epoch": 0.35046728971962615,
      "grad_norm": 1.1883083581924438,
      "learning_rate": 4.4158878504672904e-05,
      "loss": 1.2981,
      "step": 600
    },
    {
      "epoch": 0.36507009345794394,
      "grad_norm": 1.4960647821426392,
      "learning_rate": 4.39154984423676e-05,
      "loss": 1.2695,
      "step": 625
    },
    {
      "epoch": 0.3796728971962617,
      "grad_norm": 1.11279296875,
      "learning_rate": 4.367211838006231e-05,
      "loss": 1.2897,
      "step": 650
    },
    {
      "epoch": 0.3942757009345794,
      "grad_norm": 3.3723652362823486,
      "learning_rate": 4.3428738317757014e-05,
      "loss": 1.2812,
      "step": 675
    },
    {
      "epoch": 0.4088785046728972,
      "grad_norm": 1.3596960306167603,
      "learning_rate": 4.318535825545171e-05,
      "loss": 1.2809,
      "step": 700
    },
    {
      "epoch": 0.42348130841121495,
      "grad_norm": 1.7418222427368164,
      "learning_rate": 4.294197819314642e-05,
      "loss": 1.2778,
      "step": 725
    },
    {
      "epoch": 0.4380841121495327,
      "grad_norm": 1.2822264432907104,
      "learning_rate": 4.2698598130841124e-05,
      "loss": 1.2922,
      "step": 750
    },
    {
      "epoch": 0.4526869158878505,
      "grad_norm": 1.5854899883270264,
      "learning_rate": 4.245521806853583e-05,
      "loss": 1.2818,
      "step": 775
    },
    {
      "epoch": 0.4672897196261682,
      "grad_norm": 1.304915428161621,
      "learning_rate": 4.221183800623053e-05,
      "loss": 1.2858,
      "step": 800
    },
    {
      "epoch": 0.48189252336448596,
      "grad_norm": 2.4647057056427,
      "learning_rate": 4.1968457943925235e-05,
      "loss": 1.3063,
      "step": 825
    },
    {
      "epoch": 0.49649532710280375,
      "grad_norm": 1.6131970882415771,
      "learning_rate": 4.172507788161994e-05,
      "loss": 1.2998,
      "step": 850
    },
    {
      "epoch": 0.5110981308411215,
      "grad_norm": 1.4651964902877808,
      "learning_rate": 4.148169781931464e-05,
      "loss": 1.2727,
      "step": 875
    },
    {
      "epoch": 0.5257009345794392,
      "grad_norm": 1.4378418922424316,
      "learning_rate": 4.123831775700935e-05,
      "loss": 1.3033,
      "step": 900
    },
    {
      "epoch": 0.540303738317757,
      "grad_norm": 1.989951491355896,
      "learning_rate": 4.099493769470405e-05,
      "loss": 1.3088,
      "step": 925
    },
    {
      "epoch": 0.5549065420560748,
      "grad_norm": 1.9242433309555054,
      "learning_rate": 4.0751557632398756e-05,
      "loss": 1.2978,
      "step": 950
    },
    {
      "epoch": 0.5695093457943925,
      "grad_norm": 1.585597038269043,
      "learning_rate": 4.050817757009346e-05,
      "loss": 1.2688,
      "step": 975
    },
    {
      "epoch": 0.5841121495327103,
      "grad_norm": 1.4365991353988647,
      "learning_rate": 4.026479750778817e-05,
      "loss": 1.2686,
      "step": 1000
    },
    {
      "epoch": 0.5987149532710281,
      "grad_norm": 0.8879930973052979,
      "learning_rate": 4.0021417445482866e-05,
      "loss": 1.2766,
      "step": 1025
    },
    {
      "epoch": 0.6133177570093458,
      "grad_norm": 1.034176230430603,
      "learning_rate": 3.977803738317757e-05,
      "loss": 1.2892,
      "step": 1050
    },
    {
      "epoch": 0.6279205607476636,
      "grad_norm": 1.4151121377944946,
      "learning_rate": 3.953465732087228e-05,
      "loss": 1.2934,
      "step": 1075
    },
    {
      "epoch": 0.6425233644859814,
      "grad_norm": 1.232235312461853,
      "learning_rate": 3.9291277258566976e-05,
      "loss": 1.2865,
      "step": 1100
    },
    {
      "epoch": 0.657126168224299,
      "grad_norm": 1.1297640800476074,
      "learning_rate": 3.904789719626168e-05,
      "loss": 1.2917,
      "step": 1125
    },
    {
      "epoch": 0.6717289719626168,
      "grad_norm": 2.1133899688720703,
      "learning_rate": 3.880451713395639e-05,
      "loss": 1.2756,
      "step": 1150
    },
    {
      "epoch": 0.6863317757009346,
      "grad_norm": 1.190669298171997,
      "learning_rate": 3.856113707165109e-05,
      "loss": 1.2883,
      "step": 1175
    },
    {
      "epoch": 0.7009345794392523,
      "grad_norm": 1.7307356595993042,
      "learning_rate": 3.831775700934579e-05,
      "loss": 1.2593,
      "step": 1200
    },
    {
      "epoch": 0.7155373831775701,
      "grad_norm": 1.3430585861206055,
      "learning_rate": 3.8074376947040505e-05,
      "loss": 1.2574,
      "step": 1225
    },
    {
      "epoch": 0.7301401869158879,
      "grad_norm": 1.2042316198349,
      "learning_rate": 3.7830996884735204e-05,
      "loss": 1.2591,
      "step": 1250
    },
    {
      "epoch": 0.7447429906542056,
      "grad_norm": 1.240520715713501,
      "learning_rate": 3.758761682242991e-05,
      "loss": 1.2904,
      "step": 1275
    },
    {
      "epoch": 0.7593457943925234,
      "grad_norm": 1.49472177028656,
      "learning_rate": 3.7344236760124615e-05,
      "loss": 1.282,
      "step": 1300
    },
    {
      "epoch": 0.7739485981308412,
      "grad_norm": 0.9366068243980408,
      "learning_rate": 3.7100856697819314e-05,
      "loss": 1.2692,
      "step": 1325
    },
    {
      "epoch": 0.7885514018691588,
      "grad_norm": 1.3436166048049927,
      "learning_rate": 3.685747663551402e-05,
      "loss": 1.2745,
      "step": 1350
    },
    {
      "epoch": 0.8031542056074766,
      "grad_norm": 1.0009753704071045,
      "learning_rate": 3.6614096573208725e-05,
      "loss": 1.307,
      "step": 1375
    },
    {
      "epoch": 0.8177570093457944,
      "grad_norm": 0.9097902178764343,
      "learning_rate": 3.637071651090343e-05,
      "loss": 1.2801,
      "step": 1400
    },
    {
      "epoch": 0.8323598130841121,
      "grad_norm": 1.1544891595840454,
      "learning_rate": 3.612733644859813e-05,
      "loss": 1.2578,
      "step": 1425
    },
    {
      "epoch": 0.8469626168224299,
      "grad_norm": 1.488891839981079,
      "learning_rate": 3.5883956386292835e-05,
      "loss": 1.2637,
      "step": 1450
    },
    {
      "epoch": 0.8615654205607477,
      "grad_norm": 1.09141206741333,
      "learning_rate": 3.564057632398754e-05,
      "loss": 1.2838,
      "step": 1475
    },
    {
      "epoch": 0.8761682242990654,
      "grad_norm": 1.7092291116714478,
      "learning_rate": 3.5397196261682246e-05,
      "loss": 1.2853,
      "step": 1500
    }
  ],
  "logging_steps": 25,
  "max_steps": 5136,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 6447107801088000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
