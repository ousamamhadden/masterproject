{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: transformers in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Reviews per Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16976743</td>\n",
       "      <td>Charming yet Trendy Retreat- in my 2 bedroom w...</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556848</td>\n",
       "      <td>Grab your friends and make this two bedroom Br...</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240918</td>\n",
       "      <td>A private bedroom in a shared apartment. One b...</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4759718</td>\n",
       "      <td>BEFORE BOOKING: PRIVATE rental only, June to A...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2591213</td>\n",
       "      <td>Beautiful  private room on the garden/basement...</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                            Summary  \\\n",
       "0  16976743  Charming yet Trendy Retreat- in my 2 bedroom w...   \n",
       "1   6556848  Grab your friends and make this two bedroom Br...   \n",
       "2    240918  A private bedroom in a shared apartment. One b...   \n",
       "3   4759718  BEFORE BOOKING: PRIVATE rental only, June to A...   \n",
       "4   2591213  Beautiful  private room on the garden/basement...   \n",
       "\n",
       "   Reviews per Month  \n",
       "0               1.02  \n",
       "1               0.44  \n",
       "2               1.96  \n",
       "3               0.25  \n",
       "4               2.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "df = pd.read_csv('datasetV2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = df.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Reviews per Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16976743</td>\n",
       "      <td>Charming yet Trendy Retreat- in my 2 bedroom w...</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6556848</td>\n",
       "      <td>Grab your friends and make this two bedroom Br...</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240918</td>\n",
       "      <td>A private bedroom in a shared apartment. One b...</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4759718</td>\n",
       "      <td>BEFORE BOOKING: PRIVATE rental only, June to A...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2591213</td>\n",
       "      <td>Beautiful  private room on the garden/basement...</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15449</th>\n",
       "      <td>6967723</td>\n",
       "      <td>PERFECT FOR YOUNG, EDGY PEOPLE LOOKING FOR AN ...</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15450</th>\n",
       "      <td>165461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>15799340</td>\n",
       "      <td>Private STUDIO w/private kitchen in one bedroo...</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15452</th>\n",
       "      <td>3053443</td>\n",
       "      <td>My home is in the very center of San Francisco...</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15453</th>\n",
       "      <td>14789464</td>\n",
       "      <td>My place is close to Lake Michigan/Montrose Be...</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15454 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                            Summary  \\\n",
       "0      16976743  Charming yet Trendy Retreat- in my 2 bedroom w...   \n",
       "1       6556848  Grab your friends and make this two bedroom Br...   \n",
       "2        240918  A private bedroom in a shared apartment. One b...   \n",
       "3       4759718  BEFORE BOOKING: PRIVATE rental only, June to A...   \n",
       "4       2591213  Beautiful  private room on the garden/basement...   \n",
       "...         ...                                                ...   \n",
       "15449   6967723  PERFECT FOR YOUNG, EDGY PEOPLE LOOKING FOR AN ...   \n",
       "15450    165461                                                NaN   \n",
       "15451  15799340  Private STUDIO w/private kitchen in one bedroo...   \n",
       "15452   3053443  My home is in the very center of San Francisco...   \n",
       "15453  14789464  My place is close to Lake Michigan/Montrose Be...   \n",
       "\n",
       "       Reviews per Month  \n",
       "0                   1.02  \n",
       "1                   0.44  \n",
       "2                   1.96  \n",
       "3                   0.25  \n",
       "4                   2.33  \n",
       "...                  ...  \n",
       "15449               1.77  \n",
       "15450               0.69  \n",
       "15451               5.14  \n",
       "15452               1.82  \n",
       "15453               3.11  \n",
       "\n",
       "[15454 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Check if GPU is available\\nif torch.cuda.is_available():\\n    # Set the default tensor type to CUDA tensor\\n    torch.set_default_tensor_type(torch.cuda.FloatTensor)\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\ntorch.set_default_device(device)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertPreTrainedModel, BertModel, BertTokenizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "\n",
    "'''\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the default tensor type to CUDA tensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.set_default_device(device)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM']= \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SummaryClean']= df['Summary'].map(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15454"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.SummaryClean.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "encoded_corpus = tokenizer(text=df.SummaryClean.tolist(),\n",
    "                            add_special_tokens=True,\n",
    "                            padding='max_length',\n",
    "                            truncation='longest_first',\n",
    "                            max_length=200,\n",
    "                            return_attention_mask=True)\n",
    "input_ids = encoded_corpus['input_ids']\n",
    "attention_mask = encoded_corpus['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Reviews per Month'].map(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.1\n",
    "seed = 42\n",
    "train_inputs, test_inputs, train_labels, test_labels = \\\n",
    "            train_test_split(input_ids, labels, test_size=test_size, \n",
    "                             random_state=seed)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, \n",
    "                                        labels, test_size=test_size, \n",
    "                                        random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "price_scaler = StandardScaler()\n",
    "price_scaler.fit(train_labels.to_numpy().reshape(-1, 1))\n",
    "train_labels = price_scaler.transform(train_labels.to_numpy().reshape(-1, 1))\n",
    "test_labels = price_scaler.transform(test_labels.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "batch_size = 16\n",
    "def create_dataloaders(inputs, masks, labels, batch_size):\n",
    "    input_tensor = torch.tensor(inputs)\n",
    "    mask_tensor = torch.tensor(masks)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    dataset = TensorDataset(input_tensor, mask_tensor, \n",
    "                            labels_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            shuffle=False)\n",
    "    return dataloader\n",
    "train_dataloader = create_dataloaders(train_inputs, train_masks, \n",
    "                                      train_labels, batch_size)\n",
    "test_dataloader = create_dataloaders(test_inputs, test_masks, \n",
    "                                     test_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "class BertRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self, drop_rate=0.2, freeze_bert=True):\n",
    "        super(BertRegressor, self).__init__()\n",
    "        D_in, D_out = 768, 1\n",
    "        self.bert = \\\n",
    "                   BertModel.from_pretrained(MODEL_NAME)\n",
    "        '''for param in self.bert.parameters():\n",
    "            param.requires_grad = False'''\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(D_in, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(128, D_out)\n",
    "            )\n",
    "        self.double()\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        \n",
    "        outputs = self.bert(input_ids, attention_masks)\n",
    "        class_label_output = outputs[1]\n",
    "        outputs = self.regressor(class_label_output)\n",
    "        return outputs\n",
    "model = BertRegressor(drop_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(\"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertRegressor(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/anaconda3/envs/newenvn/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=5e-5,\n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 3\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,       \n",
    "                 num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    output = []\n",
    "    labels = []\n",
    "    for batch in dataloader:\n",
    "        batch_inputs, batch_masks, label = \\\n",
    "                                  tuple(b.to(device) for b in batch)\n",
    "        with torch.no_grad():\n",
    "            output += model(batch_inputs, \n",
    "                            batch_masks)\n",
    "            labels += label\n",
    "    return output, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1():\n",
    "        test_dataloader2 = create_dataloaders(test_inputs, test_masks, \n",
    "                                test_labels, 1)\n",
    "        y_pred_scaled2, labels2 = predict(model, test_dataloader2, device)\n",
    "        y_test2= list(map(lambda x : x.to(\"cpu\").numpy()[0], labels2))\n",
    "        y_pred2= list(map(lambda x : x.to(\"cpu\").numpy()[0], y_pred_scaled2))\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        from sklearn.metrics import median_absolute_error\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.metrics import mean_absolute_percentage_error\n",
    "        from sklearn.metrics import r2_score\n",
    "        mae = mean_absolute_error(y_test2, y_pred2)\n",
    "        mdae = median_absolute_error(y_test2, y_pred2)\n",
    "        mse = mean_squared_error(y_test2, y_pred2)\n",
    "        mape = mean_absolute_percentage_error(y_test2, y_pred2)\n",
    "        #mdape = ((pd.Series(y_test) - pd.Series(y_pred))\\\n",
    "                # / pd.Series(y_test)).abs().median()\n",
    "        r_squared = r2_score(y_test2, y_pred2)\n",
    "        print(mae, mdae, mse, mape, r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2():\n",
    "        test_dataloader2 = create_dataloaders(train_inputs, train_masks, \n",
    "                                train_labels, 1)\n",
    "        y_pred_scaled2, labels2 = predict(model, test_dataloader2, device)\n",
    "        y_test2= list(map(lambda x : x.to(\"cpu\").numpy()[0], labels2))\n",
    "        y_pred2= list(map(lambda x : x.to(\"cpu\").numpy()[0], y_pred_scaled2))\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        from sklearn.metrics import median_absolute_error\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.metrics import mean_absolute_percentage_error\n",
    "        from sklearn.metrics import r2_score\n",
    "        mae = mean_absolute_error(y_test2, y_pred2)\n",
    "        mdae = median_absolute_error(y_test2, y_pred2)\n",
    "        mse = mean_squared_error(y_test2, y_pred2)\n",
    "        mape = mean_absolute_percentage_error(y_test2, y_pred2)\n",
    "        #mdape = ((pd.Series(y_test) - pd.Series(y_pred))\\\n",
    "                # / pd.Series(y_test)).abs().median()\n",
    "        r_squared = r2_score(y_test2, y_pred2)\n",
    "        print(mae, mdae, mse, mape, r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def r2_score(outputs, labels):\n",
    "    labels_mean = torch.mean(labels)\n",
    "    ss_tot = torch.sum((labels - labels_mean) ** 2)\n",
    "    ss_res = torch.sum((labels - outputs) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-----\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "def train(model, optimizer, scheduler, loss_function, epochs,       \n",
    "          train_dataloader, device, clip_value=2):\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        print(\"-----\")\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader): \n",
    "            print(step)  \n",
    "            batch_inputs, batch_masks, batch_labels = \\\n",
    "                               tuple(b.to(device) for b in batch)\n",
    "            model.zero_grad()\n",
    "            outputs = model(batch_inputs, batch_masks)     \n",
    "                \n",
    "            loss = (loss_function(outputs.squeeze(), \n",
    "                             batch_labels.squeeze()))\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        evaluate1()\n",
    "        evaluate1()\n",
    "                \n",
    "    return model\n",
    "model = train(model, optimizer, scheduler, loss_function, epochs, \n",
    "              train_dataloader, device, clip_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_scaled, labels = predict(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''y_test= labels\n",
    "y_pred = y_pred_scaled'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test= list(map(lambda x : x.to(\"cpu\").numpy()[0], labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = list(map(lambda x : x.to(\"cpu\").numpy()[0], y_pred_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.023064011837874085,\n",
       " -0.10991329677906922,\n",
       " -0.05402781242897528,\n",
       " 0.05508394453169933,\n",
       " -0.17078740765062764,\n",
       " -0.20052938036584114,\n",
       " -0.2323236041217319,\n",
       " -0.20790779139990276,\n",
       " 0.10572542415406282,\n",
       " -0.15537824670527986,\n",
       " 0.03081146681085495,\n",
       " -0.09967908904861547,\n",
       " -0.10491911290311268,\n",
       " 0.06310059502342544,\n",
       " -0.04634752524509919,\n",
       " -0.14868289646757366,\n",
       " 0.061789579514265704,\n",
       " -0.16430775794658306,\n",
       " 0.005901065482177531,\n",
       " -0.026196783438810864,\n",
       " -0.06426587381796706,\n",
       " 0.07697857556329785,\n",
       " -0.07307595831961775,\n",
       " -0.038953498535157005,\n",
       " 0.128182429764538,\n",
       " -0.03129068158921114,\n",
       " -0.22323336197761343,\n",
       " 0.05877904084934935,\n",
       " -0.0330344880219416,\n",
       " 0.15945316672067938,\n",
       " 0.14725612563745025,\n",
       " -0.15699464177144004,\n",
       " -0.12674356450853716,\n",
       " -0.060681201303760146,\n",
       " -0.01585626681583395,\n",
       " -0.10636627396045303,\n",
       " 0.09331280344864536,\n",
       " -0.16628836912672965,\n",
       " 0.08664041216296564,\n",
       " -0.1840831352660747,\n",
       " -0.048489791173552815,\n",
       " 0.18276843020326106,\n",
       " -0.012601398392319996,\n",
       " 0.05891683060622872,\n",
       " -0.08281748083321078,\n",
       " -0.08989058270307046,\n",
       " 0.030071562604357692,\n",
       " -0.1060506193166286,\n",
       " -0.048749929674899745,\n",
       " -0.026394917814857352,\n",
       " -0.0022269644268243932,\n",
       " 0.11223269458876847,\n",
       " 0.11667031788869432,\n",
       " -0.1983418294011098,\n",
       " 0.20701329331525553,\n",
       " 0.04881976642917033,\n",
       " 0.06868374687779892,\n",
       " 0.09326454085382786,\n",
       " 0.07978553163508205,\n",
       " -0.054874316852781685,\n",
       " -0.1339948301517021,\n",
       " 0.028112823998676643,\n",
       " -0.1853725634534528,\n",
       " 0.04607706401981221,\n",
       " 0.037837006709385834,\n",
       " 0.09644053484908038,\n",
       " 0.10934306702434182,\n",
       " 0.09950059012941445,\n",
       " -0.14883055253678168,\n",
       " -0.03815127633072307,\n",
       " -0.12674989073046591,\n",
       " -0.20617783211466642,\n",
       " -0.15918051207715475,\n",
       " 0.006616689127546413,\n",
       " -0.006470411412179619,\n",
       " -0.02049991333369583,\n",
       " -0.09252298312331442,\n",
       " -0.11400989581938134,\n",
       " 0.11429034831636284,\n",
       " -0.08244599783758849,\n",
       " -0.18391606856660606,\n",
       " 0.15007182877269523,\n",
       " -0.15007007321872307,\n",
       " 0.12462080371811135,\n",
       " -0.19018024668006003,\n",
       " 0.03414130968819667,\n",
       " 0.03471003967544574,\n",
       " -0.0033507609005046096,\n",
       " 0.06676322517577643,\n",
       " -0.03711298896090888,\n",
       " -0.025072452115705926,\n",
       " 0.18258782876405527,\n",
       " 0.18189407100057364,\n",
       " -0.06973763636904806,\n",
       " 0.05460420931216511,\n",
       " 0.11591480000253317,\n",
       " -0.06185730778985729,\n",
       " 0.07230621269418826,\n",
       " -0.154792049196036,\n",
       " -0.04359862795490729,\n",
       " -0.08453422806659747,\n",
       " -0.5890122914369856,\n",
       " 0.10929698895206574,\n",
       " -0.008340804400758295,\n",
       " 0.12903807736337367,\n",
       " 0.04420929617286687,\n",
       " 0.16541975157238553,\n",
       " -0.10002091489936757,\n",
       " 0.21158569395817423,\n",
       " -0.03745180033808772,\n",
       " 0.02515875674659654,\n",
       " -0.05487171691529702,\n",
       " -0.07852230087433507,\n",
       " -0.14951926868221027,\n",
       " -0.5890122914369856,\n",
       " -0.016021265279849872,\n",
       " -0.15844039731599724,\n",
       " 0.03331130437347072,\n",
       " -0.20646059419196314,\n",
       " -0.5890122914369856,\n",
       " 0.06434343031402542,\n",
       " 0.09549925167057938,\n",
       " -0.06385519201418657,\n",
       " 0.164931602562273,\n",
       " 0.00860919482533963,\n",
       " -0.015880229768292606,\n",
       " -0.06806236909245184,\n",
       " -0.1333041040546438,\n",
       " 0.126628757555303,\n",
       " -0.02237494825428822,\n",
       " -0.019321694747992696,\n",
       " 0.006057826158115384,\n",
       " 0.03978554632692088,\n",
       " -0.12313452743014905,\n",
       " -0.2122759668044251,\n",
       " -0.05164699432921353,\n",
       " -0.007882666215256448,\n",
       " -0.0033544489767310948,\n",
       " 0.057931631437310394,\n",
       " 0.0275909181806699,\n",
       " 0.1264942132477209,\n",
       " -0.13489492588094773,\n",
       " -0.1551853441857523,\n",
       " 0.17235296175660542,\n",
       " 0.10665370938017607,\n",
       " 0.11526021657505545,\n",
       " -0.11454248919035168,\n",
       " -0.5890122914369856,\n",
       " 0.03627424092472017,\n",
       " 0.19690646141446813,\n",
       " 0.07622146387522391,\n",
       " 0.07500391592118005,\n",
       " 0.01577339552092301,\n",
       " 0.014392127682484629,\n",
       " -0.009596838149262946,\n",
       " 0.11633805753733667,\n",
       " -0.02724034737150116,\n",
       " -0.047032907239683536,\n",
       " -0.08607912958038066,\n",
       " 0.1496243673617455,\n",
       " 0.08784877482108847,\n",
       " -0.21655178476702916,\n",
       " -0.08984873454685607,\n",
       " 0.07399230051895808,\n",
       " -0.08365446905934451,\n",
       " -0.07491796389092625,\n",
       " -0.5890122914369856,\n",
       " 0.26619686081228866,\n",
       " 0.014611639284060993,\n",
       " -0.1248415194208016,\n",
       " 0.11223431908020864,\n",
       " -0.04297298440726814,\n",
       " -0.009133187330609777,\n",
       " 0.16678437114446262,\n",
       " 0.13898687219227335,\n",
       " -0.13161114634243343,\n",
       " -0.16352391877961778,\n",
       " 0.07038186192341968,\n",
       " 0.13413733149392076,\n",
       " -0.11589768089545846,\n",
       " 0.04914143519068611,\n",
       " -0.2076030874897363,\n",
       " 0.19678739557794414,\n",
       " -0.03208222428288017,\n",
       " -0.13245137312475358,\n",
       " 0.0427200611597265,\n",
       " -0.5890122914369856,\n",
       " 0.028692948078206874,\n",
       " -0.07193577945193441,\n",
       " 0.08129700263752015,\n",
       " 0.16873879935087366,\n",
       " -0.1606378623869498,\n",
       " -0.03609961771263888,\n",
       " -0.06253936203693575,\n",
       " -0.18706006838324382,\n",
       " 0.0847223386034597,\n",
       " 0.022357663447033896,\n",
       " -0.07998534200996477,\n",
       " -0.09635757974035938,\n",
       " 0.18955519768283657,\n",
       " -0.07280843726561473,\n",
       " 0.13884955882652086,\n",
       " 0.014905893773470173,\n",
       " -0.12629522754410327,\n",
       " 0.05171822414157737,\n",
       " -0.06998253943560989,\n",
       " 0.0015502775638891186,\n",
       " -0.017270520806871373,\n",
       " 0.06084370748316041,\n",
       " 0.019406799249666054,\n",
       " 0.080643893683472,\n",
       " 0.1185497906629064,\n",
       " 0.04426351507405261,\n",
       " -0.24355920522183014,\n",
       " -0.038372889023185724,\n",
       " -0.11696402321860783,\n",
       " -0.12072048341209435,\n",
       " 0.25154316031581625,\n",
       " -0.07356034717244625,\n",
       " -0.03553053477817661,\n",
       " -0.0376908292653932,\n",
       " 0.01520157421326744,\n",
       " -0.006474142428797666,\n",
       " 0.06502188289864867,\n",
       " 0.1544541673688543,\n",
       " 0.18566145083545724,\n",
       " 0.10109653589340221,\n",
       " 0.18423672725463383,\n",
       " -0.176922545749691,\n",
       " 0.0181192526343181,\n",
       " 0.11214192195485254,\n",
       " 0.12057788181489056,\n",
       " 0.23954535527625334,\n",
       " -0.09714013986454734,\n",
       " -0.5890122914369856,\n",
       " -0.15719006718389425,\n",
       " -0.1661322739375812,\n",
       " 0.09758712117335658,\n",
       " 0.007801617848862755,\n",
       " 0.14520785038198328,\n",
       " -0.22623936445968987,\n",
       " 0.015616837668839437,\n",
       " -0.07935933399488684,\n",
       " -0.10966774687099418,\n",
       " -0.13294704084617634,\n",
       " 0.03816853563876294,\n",
       " -0.1121363179325072,\n",
       " 0.15188333420847938,\n",
       " 0.13385609935078413,\n",
       " -0.07825984038691727,\n",
       " 0.04978843585535295,\n",
       " -0.14336773168012695,\n",
       " -0.07326158735314203,\n",
       " -0.09852694628760295,\n",
       " -0.05551606375957979,\n",
       " 0.03280840901474941,\n",
       " -0.049072815344998105,\n",
       " -0.5890122914369856,\n",
       " 0.05589193616354296,\n",
       " -0.08004315166646078,\n",
       " -0.012025948783047802,\n",
       " 0.02665460784976867,\n",
       " -0.1439213481734442,\n",
       " 0.024604918491663158,\n",
       " 0.17534688965283782,\n",
       " 0.09767414810310905,\n",
       " 0.054686052083618486,\n",
       " 0.16277876902765293,\n",
       " -0.07986589376437483,\n",
       " 0.038453347572657226,\n",
       " 0.07926895029020431,\n",
       " 0.09583621362506539,\n",
       " -0.008423391914705855,\n",
       " 0.035499773123106454,\n",
       " -0.20243679485256247,\n",
       " -0.5890122914369856,\n",
       " 0.14290716712713936,\n",
       " 0.1721706668389425,\n",
       " -0.08426215929895356,\n",
       " 0.024228803113180958,\n",
       " -0.01145106601433693,\n",
       " 0.042263640742308504,\n",
       " -0.028318164955836556,\n",
       " -0.5890122914369856,\n",
       " 0.05587796380894701,\n",
       " -0.07270436976150219,\n",
       " -0.12822612732598362,\n",
       " -0.024693513821203453,\n",
       " 0.14377796916713081,\n",
       " 0.0561122598815989,\n",
       " -0.20194339372095402,\n",
       " -0.08101864130119882,\n",
       " 0.15641456799688552,\n",
       " -0.007876406876724529,\n",
       " 0.02384390755912666,\n",
       " -0.06801430816981466,\n",
       " -0.09049617583914396,\n",
       " -0.008691548170028568,\n",
       " -0.09585703632413217,\n",
       " -0.0819085317085714,\n",
       " 0.030558998630311217,\n",
       " -0.08972763496412134,\n",
       " 0.06655673643838282,\n",
       " -0.07475662457055254,\n",
       " -0.06742509646481448,\n",
       " -0.15071290373706708,\n",
       " 0.0538018729868134,\n",
       " -0.007156146007163147,\n",
       " -0.14454911072857235,\n",
       " -0.5890122914369856,\n",
       " 0.11120518803969616,\n",
       " 0.007899084184243982,\n",
       " 0.28018236346046765,\n",
       " 0.011847219366158915,\n",
       " 0.04079167523131773,\n",
       " 0.01882201632497915,\n",
       " -0.1474046550125077,\n",
       " -0.12449565534353224,\n",
       " -0.17650230131397773,\n",
       " -0.19227707774839495,\n",
       " 0.18834956256518262,\n",
       " 0.0671658701693885,\n",
       " -0.18171811100962423,\n",
       " 0.1065537477419862,\n",
       " 0.029080435143562622,\n",
       " 0.1836815528929372,\n",
       " 0.05680788992079264,\n",
       " 0.031872130364590766,\n",
       " -0.1402454780042818,\n",
       " 0.015536576995344165,\n",
       " 0.1194063863300698,\n",
       " -0.19789382801103247,\n",
       " -0.16336776706360737,\n",
       " -0.024680085552452408,\n",
       " -0.21249405531680501,\n",
       " 0.15406446174175592,\n",
       " 0.13385085908632338,\n",
       " -0.09744855935717586,\n",
       " -0.24043567272805613,\n",
       " -0.5890122914369856,\n",
       " 0.014880048995761182,\n",
       " -0.5890122914369856,\n",
       " -0.19630635773502733,\n",
       " -0.14956323323438034,\n",
       " 0.0056115566911120185,\n",
       " -0.02288489029769314,\n",
       " -0.029062203428940794,\n",
       " 0.14929444030618705,\n",
       " -0.0648317259310201,\n",
       " -0.0009835592737008902,\n",
       " -0.006259957756412221,\n",
       " 0.06823498045909447,\n",
       " -0.08363120164019891,\n",
       " -0.11208135120230825,\n",
       " -0.15491871461080128,\n",
       " -0.010471301115695011,\n",
       " -0.061962105372380644,\n",
       " 0.10823926456854496,\n",
       " -0.09094111199402702,\n",
       " 0.09423402232465415,\n",
       " -0.12099553817758624,\n",
       " 0.08372671289136206,\n",
       " -0.5890122914369856,\n",
       " -0.13352538902846378,\n",
       " -0.14812680857083285,\n",
       " 0.08596754596098666,\n",
       " -0.1226631322091897,\n",
       " 0.03376518703488194,\n",
       " 0.09879480221850324,\n",
       " 0.010111982135308839,\n",
       " 0.03733585529623966,\n",
       " 0.1267657735192106,\n",
       " -0.018374342731619128,\n",
       " -0.06069283477475293,\n",
       " -0.03008654763902746,\n",
       " 0.021306261491929365,\n",
       " 0.11863400300629598,\n",
       " -0.09491775357176152,\n",
       " -0.21315162144265817,\n",
       " -0.17098270842956517,\n",
       " -0.038202893750376485,\n",
       " -0.12532903639534676,\n",
       " 0.1708628821287244,\n",
       " 0.02247283006458503,\n",
       " -0.0009071380935491563,\n",
       " -0.07617593619964488,\n",
       " 0.04751274028835966,\n",
       " -0.5890122914369856,\n",
       " -0.2117042657050052,\n",
       " 0.006138271805122011,\n",
       " 0.000991490506650039,\n",
       " -0.1292448851704229,\n",
       " -0.05667662285456701,\n",
       " -0.08653422913668493,\n",
       " -0.11541096210846244,\n",
       " 0.006565113045772078,\n",
       " -0.2194785145957018,\n",
       " -0.01814945140578371,\n",
       " 0.2553840873676193,\n",
       " 0.20944468132299413,\n",
       " -0.12543805468165914,\n",
       " -0.055062926131491496,\n",
       " -0.02163663559570038,\n",
       " 0.16845759707597885,\n",
       " -0.024211411804959032,\n",
       " 0.14608168629426324,\n",
       " -0.1258549022055672,\n",
       " -0.11543649157523697,\n",
       " 0.004206116167471435,\n",
       " -0.5890122914369856,\n",
       " -0.24247025845209094,\n",
       " -0.17646249213453033,\n",
       " 0.18275408184691386,\n",
       " -0.09988705781801496,\n",
       " 0.12933638643039835,\n",
       " 0.07662892387547152,\n",
       " -0.054013750080434075,\n",
       " 0.11895362986356156,\n",
       " 0.07176733317473036,\n",
       " -0.5890122914369856,\n",
       " -0.02019607895664105,\n",
       " -0.06373848887688563,\n",
       " -0.5890122914369856,\n",
       " 0.17717200858142962,\n",
       " 0.007774095317412993,\n",
       " -0.0313371116095556,\n",
       " -0.018496879992842732,\n",
       " -0.0975252219635803,\n",
       " 0.14435023483892306,\n",
       " -0.13425545558453753,\n",
       " 0.2099651168618499,\n",
       " -0.011539955269402422,\n",
       " -0.03870989940163233,\n",
       " 0.010598026795627317,\n",
       " 0.12284755947615958,\n",
       " 0.10403179228677663,\n",
       " -0.239912636825562,\n",
       " 0.06069041852779092,\n",
       " 0.016294916247485608,\n",
       " -0.021729019459454504,\n",
       " -0.019479215578098827,\n",
       " 0.011280036702864003,\n",
       " 0.20105975050712085,\n",
       " 0.26022135710371463,\n",
       " -0.10298995886525522,\n",
       " -0.007701492605803481,\n",
       " -0.04632636942190818,\n",
       " 0.12844225063385833,\n",
       " 0.1199248860134861,\n",
       " -0.04932757633711109,\n",
       " 0.1047503299063383,\n",
       " 0.19080276530599388,\n",
       " -0.11081565098734927,\n",
       " -0.005615003376746017,\n",
       " 0.14191485318972283,\n",
       " -0.1287947990760203,\n",
       " -0.16039747751507505,\n",
       " -0.04139044877947076,\n",
       " -0.1295124103018965,\n",
       " -0.16772504772670596,\n",
       " 0.2049189502497798,\n",
       " -0.00744984832431525,\n",
       " -0.21916157364279418,\n",
       " -0.04785770509093172,\n",
       " -0.2187947282400606,\n",
       " -0.13771101527621107,\n",
       " 0.09664151038788525,\n",
       " 0.1491403661160574,\n",
       " -0.055564579237294326,\n",
       " -0.14261189820342635,\n",
       " -0.09291084026149193,\n",
       " 0.006010980294411036,\n",
       " -0.21476102196863886,\n",
       " -0.07681668582974852,\n",
       " -0.15496076437075967,\n",
       " -0.08973052648383442,\n",
       " -0.1434707126204233,\n",
       " -0.11746991913900157,\n",
       " -0.05441130967800381,\n",
       " -0.5890122914369856,\n",
       " 0.10918089615767376,\n",
       " -0.1456185343903341,\n",
       " -0.03484516497081003,\n",
       " 0.15144290765548488,\n",
       " 0.000381142662120304,\n",
       " -0.015108608634600423,\n",
       " -0.15098745463816785,\n",
       " -0.11678666825405803,\n",
       " -0.14812350749074624,\n",
       " -0.1255231404439005,\n",
       " -0.18250685608330328,\n",
       " 0.2140008485280764,\n",
       " -0.15762818989770355,\n",
       " -0.09021651243987316,\n",
       " -0.15680131309444578,\n",
       " -0.5890122914369856,\n",
       " -0.23223443925629886,\n",
       " -0.14355409842851186,\n",
       " 0.11059346199647967,\n",
       " 0.006933517686007695,\n",
       " -0.15865633143287874,\n",
       " 0.08432683159005963,\n",
       " -0.04540288848023773,\n",
       " -0.1032396867563965,\n",
       " 0.15179985203254015,\n",
       " 0.16258534338862424,\n",
       " -0.057536564088037145,\n",
       " 0.11451395791923352,\n",
       " -0.02543358693579309,\n",
       " -0.0902565520811,\n",
       " -0.5890122914369856,\n",
       " -0.02261388420297901,\n",
       " 0.01541829706530691,\n",
       " -0.1351072196479764,\n",
       " 0.10652178390532935,\n",
       " 0.033761516337498396,\n",
       " 0.046913749117398075,\n",
       " 0.1335389365019266,\n",
       " 0.06920653524151449,\n",
       " 0.13582785588345314,\n",
       " 0.06719179171701735,\n",
       " -0.5890122914369856,\n",
       " 0.18793470572624577,\n",
       " -0.058169594493554105,\n",
       " -0.1408310834120962,\n",
       " -0.11595286286057957,\n",
       " 0.16575482741731543,\n",
       " 0.13230346963369186,\n",
       " 0.17278462521981475,\n",
       " 0.055774625668343125,\n",
       " -0.009160446427416896,\n",
       " -0.0666512690669191,\n",
       " 0.029734390140670815,\n",
       " -0.04112773292891918,\n",
       " -0.18354174339396082,\n",
       " 0.01290580042444698,\n",
       " -0.023570567030219966,\n",
       " -0.018479544522786814,\n",
       " -0.019981212102284374,\n",
       " -0.02420600417648275,\n",
       " -0.13127110630000233,\n",
       " -0.012182185591536415,\n",
       " 0.04463012695894893,\n",
       " -0.03056069004756498,\n",
       " 0.09602380701952248,\n",
       " -0.14588779310073802,\n",
       " -0.12187497282894938,\n",
       " -0.07023513243978344,\n",
       " -0.061867342098427675,\n",
       " 0.09031393009528774,\n",
       " 0.11458145257218057,\n",
       " 0.1786272581314827,\n",
       " -0.12120892414977624,\n",
       " -0.030694319725750166,\n",
       " -0.02407613286946919,\n",
       " 0.027479148699802128,\n",
       " 0.06751503420775046,\n",
       " 0.08992375820001189,\n",
       " 0.019634651459468133,\n",
       " -0.11003963725127877,\n",
       " -0.14759918042503192,\n",
       " 0.10411416584446051,\n",
       " -0.04550535657334413,\n",
       " 0.04731790727405642,\n",
       " -0.1372236706036258,\n",
       " 0.08397356143310536,\n",
       " 0.019771356489935554,\n",
       " 0.039020323191798295,\n",
       " -0.17161867430932895,\n",
       " -0.12820334051113733,\n",
       " -0.13905048741612186,\n",
       " 0.09256360323136731,\n",
       " 0.03899055619078719,\n",
       " 0.03056531616951732,\n",
       " -0.08077176930345917,\n",
       " -0.12135070990235117,\n",
       " -0.1066788785706432,\n",
       " -0.13416548861683222,\n",
       " -0.026454392349789538,\n",
       " 0.06305110319437951,\n",
       " -0.11358976284069719,\n",
       " -0.09803471779405973,\n",
       " 0.05882987284494694,\n",
       " 0.008935164535670587,\n",
       " 0.16518755607469263,\n",
       " 0.13019199793204905,\n",
       " -0.17203045591594435,\n",
       " 0.18476396671532028,\n",
       " -0.12135119093713567,\n",
       " 0.07460799105345522,\n",
       " 0.25882361260653103,\n",
       " -0.10748055256938396,\n",
       " 0.12677678264817843,\n",
       " 0.16019167118690977,\n",
       " 0.11858199294702365,\n",
       " 0.19254627389672085,\n",
       " -0.08784197609926764,\n",
       " 0.1690100260150584,\n",
       " 0.06462146656640386,\n",
       " -0.08272943338148467,\n",
       " -0.000770176022376598,\n",
       " -0.13533692855755197,\n",
       " -0.5890122914369856,\n",
       " 0.07600032906551742,\n",
       " -0.010555734649675588,\n",
       " 0.03399147339080797,\n",
       " -0.059284668237707394,\n",
       " -0.10364954305426949,\n",
       " 0.08717162791800688,\n",
       " -0.00414835209118819,\n",
       " -0.03932425326512862,\n",
       " -0.02388722300371944,\n",
       " 0.09255825133014975,\n",
       " -0.00364190681540745,\n",
       " -0.017275448459463327,\n",
       " 0.07823268391398468,\n",
       " 0.08216357135408175,\n",
       " -0.015483728752571119,\n",
       " 0.1916554362506755,\n",
       " 0.013147615060002435,\n",
       " 0.02892619575411029,\n",
       " 0.11184579585122323,\n",
       " 0.07041028248159531,\n",
       " -0.5890122914369856,\n",
       " -0.027854287092391322,\n",
       " 0.11281062629195115,\n",
       " 0.10358945687033579,\n",
       " -0.038836816096183335,\n",
       " -0.06460890129210106,\n",
       " 0.04865127524330355,\n",
       " -0.09853126395943165,\n",
       " 0.2753228649240536,\n",
       " -0.10091836337003468,\n",
       " -0.10114194818227382,\n",
       " -0.17647285883592034,\n",
       " -0.04496212569218637,\n",
       " -0.047324615469358094,\n",
       " -0.16608092318759268,\n",
       " -0.1078031751419593,\n",
       " -0.12662065551930046,\n",
       " -0.17349401448752846,\n",
       " 0.027124472252564424,\n",
       " 0.11055621226087739,\n",
       " 0.09879856819949745,\n",
       " -0.0881542466950786,\n",
       " 0.09216472387873578,\n",
       " 0.06545428929163327,\n",
       " 0.03862218977178367,\n",
       " -0.14874869854045966,\n",
       " -0.20288191360730903,\n",
       " -0.3355516686080151,\n",
       " -0.13226404045693063,\n",
       " -0.04163542957808482,\n",
       " -0.24027495744997976,\n",
       " -0.5890122914369856,\n",
       " 0.16291003941977378,\n",
       " 0.17025746124175878,\n",
       " -0.2317854384005155,\n",
       " 0.10590851300773683,\n",
       " -0.11836011195897228,\n",
       " -0.1709546363487805,\n",
       " -0.11001501190594082,\n",
       " 0.013443985747550236,\n",
       " 0.15249766581909985,\n",
       " -0.19154993462123213,\n",
       " -0.18589997498413693,\n",
       " -0.03222720061253223,\n",
       " 0.006350699127494822,\n",
       " -0.06716417856014673,\n",
       " 0.1841341551064577,\n",
       " 0.21841479229373015,\n",
       " 0.060931287181606446,\n",
       " 0.2107635854087973,\n",
       " -0.14015916113761967,\n",
       " -0.04362087065451509,\n",
       " 0.0017837794028421894,\n",
       " 0.02518283908608482,\n",
       " 0.09206577937595757,\n",
       " -0.04233276347604259,\n",
       " 0.2441081621268111,\n",
       " -0.14021930557921797,\n",
       " -0.15742925741783706,\n",
       " 0.06638145150868427,\n",
       " -0.1182173864029604,\n",
       " 0.03678681110625938,\n",
       " 0.18525960141442724,\n",
       " 0.0966601880933921,\n",
       " -0.1210847262174708,\n",
       " 0.000161511590299257,\n",
       " 0.05677187806229101,\n",
       " -0.06349227282122258,\n",
       " 0.09929797096238313,\n",
       " -0.007878314153200422,\n",
       " 0.021426396825395544,\n",
       " -0.052900915327511205,\n",
       " -0.07809948743560244,\n",
       " -0.12041647642832759,\n",
       " -0.04229178082982149,\n",
       " 0.10295668684407308,\n",
       " -0.09139097067449437,\n",
       " -0.10142870186635658,\n",
       " 0.007755991866784412,\n",
       " 0.18146823788458152,\n",
       " 0.16327715645637497,\n",
       " 0.026433729274798902,\n",
       " -0.06803049024674646,\n",
       " 0.012622050930833184,\n",
       " 0.13562706982264935,\n",
       " 0.02414988643321249,\n",
       " 0.02456907429026208,\n",
       " -0.047349314508912874,\n",
       " 0.1519685959526722,\n",
       " 0.0849793766054191,\n",
       " 0.003911804585465098,\n",
       " 0.11188813937902567,\n",
       " 0.009965698878390813,\n",
       " -0.021968733781741356,\n",
       " -0.09833803502978072,\n",
       " 0.24681540460164764,\n",
       " -0.15708461507997643,\n",
       " 0.009607511467889324,\n",
       " 0.12355088907778723,\n",
       " 0.0961399979957747,\n",
       " -0.028078454715873905,\n",
       " -0.06426899450461596,\n",
       " -0.15236622559896318,\n",
       " -0.05837925199699817,\n",
       " 0.00902468732931691,\n",
       " 0.1190853262348136,\n",
       " 0.11974379639227249,\n",
       " -0.07107546447599813,\n",
       " 9.10778275120816e-05,\n",
       " -0.5890122914369856,\n",
       " 0.06692669398184725,\n",
       " 0.09063950261337511,\n",
       " -0.052468982260369196,\n",
       " 0.036395212070581405,\n",
       " 0.010291639228911242,\n",
       " 0.06418443635725996,\n",
       " -0.09709947335467467,\n",
       " 0.05507464947594331,\n",
       " -0.12423044768234198,\n",
       " -0.10707247136121753,\n",
       " 0.08096430229916926,\n",
       " -0.03397764629115933,\n",
       " -0.037242344350441714,\n",
       " 0.07529622760109446,\n",
       " -0.5890122914369856,\n",
       " -0.1750741225055386,\n",
       " 0.09040098458303888,\n",
       " 0.06973133556475686,\n",
       " 0.04426128199511864,\n",
       " -0.11340989135313953,\n",
       " 0.015306327009395368,\n",
       " 0.015224505716347196,\n",
       " -0.013485933658851923,\n",
       " -0.05338315566369642,\n",
       " -0.11859642433307688,\n",
       " -0.012860659065187657,\n",
       " -0.1772247513341005,\n",
       " -0.05746149313093735,\n",
       " -0.23455336026016324,\n",
       " 0.03749207053298975,\n",
       " -0.13121232621341264,\n",
       " -0.16796456601788867,\n",
       " -0.009568050972358286,\n",
       " 0.008175952455398705,\n",
       " -0.08604232756185226,\n",
       " -0.13158751995150342,\n",
       " -0.017229854533600042,\n",
       " -0.21945293070058944,\n",
       " -0.12723868807896846,\n",
       " -0.13490550847086957,\n",
       " 0.04620224835467471,\n",
       " -1.2044185460274859e-05,\n",
       " -0.09207953566628438,\n",
       " -0.0707747761448762,\n",
       " 0.02256449627872023,\n",
       " -0.006102576531031259,\n",
       " 0.03957017205634817,\n",
       " 0.14665006246747242,\n",
       " 0.1745237863862994,\n",
       " 0.008862939477822143,\n",
       " -0.05419717261502291,\n",
       " -0.1459575783934565,\n",
       " -0.04212704890100888,\n",
       " -0.1053402394482964,\n",
       " -0.004916342169108301,\n",
       " -0.03457050646979802,\n",
       " 0.027312626748704237,\n",
       " -0.049216905556961635,\n",
       " -0.09491255178927496,\n",
       " -0.10898366502420173,\n",
       " 0.074042738162408,\n",
       " -0.1444129148198973,\n",
       " -0.16798130936356673,\n",
       " -0.05751388260745932,\n",
       " -0.0808228113583132,\n",
       " 0.1578270613719172,\n",
       " 0.1185483123294408,\n",
       " 0.054548670745650486,\n",
       " 0.16735512266108965,\n",
       " -0.04073795552336741,\n",
       " 0.1198946794052431,\n",
       " -0.05737380688963489,\n",
       " 0.06412939921204791,\n",
       " 0.03930126875695286,\n",
       " -0.04720667072613323,\n",
       " 0.13342796257342826,\n",
       " 0.1860428716033211,\n",
       " 0.18105644256526518,\n",
       " 0.14612929483209736,\n",
       " 0.016573929626226752,\n",
       " 0.10370767362476459,\n",
       " -0.08898439751667095,\n",
       " -0.06838621283101451,\n",
       " -0.2160446787891719,\n",
       " 0.16423571783237673,\n",
       " -0.14555922146517966,\n",
       " 0.1481651747646507,\n",
       " 0.003213187233893841,\n",
       " -0.1575539436656083,\n",
       " -0.04555598926937146,\n",
       " -0.07652792078481882,\n",
       " -0.12254290245935162,\n",
       " -0.0668158851056854,\n",
       " -0.038198728810825866,\n",
       " -0.14348342848965723,\n",
       " 0.0021367903831065876,\n",
       " 0.08015796814289594,\n",
       " -0.08368543775322718,\n",
       " -0.22939058561254375,\n",
       " -0.13220930480592932,\n",
       " 0.0626107321946006,\n",
       " -0.20917195858211532,\n",
       " -0.07054435620637559,\n",
       " 0.08972130113684954,\n",
       " -0.10060396590003515,\n",
       " 0.1340621040163884,\n",
       " 0.04979251099221153,\n",
       " -0.053076750009378004,\n",
       " 0.028361356613325,\n",
       " 0.12871693435002635,\n",
       " 0.1499088019071147,\n",
       " 0.10563625448067787,\n",
       " -0.5890122914369856,\n",
       " 0.007755991866784412,\n",
       " -0.14679696121655061,\n",
       " -0.18979401742832222,\n",
       " 0.12615249969066528,\n",
       " 0.08906382603048571,\n",
       " -0.11791256598460054,\n",
       " 0.14316243715560717,\n",
       " -0.09113381101629428,\n",
       " -0.04846007384942942,\n",
       " -0.08633044027409745,\n",
       " 0.14075586724643724,\n",
       " 0.03837149306123948,\n",
       " -0.05170494619103956,\n",
       " -0.07386658791673126,\n",
       " 0.05505145479806697,\n",
       " 0.00858962693635161,\n",
       " -0.13849886011798185,\n",
       " 0.08287735445476492,\n",
       " 0.12700213031427546,\n",
       " 0.2080199079205218,\n",
       " 0.060409497984744376,\n",
       " -0.0631339232281034,\n",
       " 0.03488186257102674,\n",
       " -0.08262083419470007,\n",
       " -0.06214037575402567,\n",
       " 0.12607202381426222,\n",
       " -0.09013952865580446,\n",
       " 0.1768864540523758,\n",
       " 0.0805151752897295,\n",
       " -0.18880898275943728,\n",
       " -0.10207550219956368,\n",
       " -0.1894779353311236,\n",
       " 0.031111181401451533,\n",
       " 0.09684787309458326,\n",
       " -0.09393428259799694,\n",
       " -0.18542509858571535,\n",
       " -0.12864381522974502,\n",
       " -0.19129271454021743,\n",
       " -0.1974958384684233,\n",
       " 0.018831527887057033,\n",
       " -0.005935764856020362,\n",
       " -0.10437506086372605,\n",
       " 0.15948679417521444,\n",
       " 0.1099018496254567,\n",
       " 0.1054331906632928,\n",
       " 0.05804290978323977,\n",
       " 0.08333082494607034,\n",
       " -0.00682335040882813,\n",
       " 0.002562307483734108,\n",
       " 0.0004150212666365338,\n",
       " 0.05615194863314273,\n",
       " 0.02244626699265489,\n",
       " -0.02309181927576459,\n",
       " -0.13897884228992705,\n",
       " -0.031092986422425334,\n",
       " -0.5890122914369856,\n",
       " -0.14015578045745816,\n",
       " 0.133824738578583,\n",
       " -0.031845413198189704,\n",
       " -0.08940079211474483,\n",
       " 0.15774105548834916,\n",
       " -0.1415618125993859,\n",
       " 0.06335756438649608,\n",
       " -0.137305510656192,\n",
       " -0.07541728867504441,\n",
       " -0.10157452023565394,\n",
       " -0.13191895867188475,\n",
       " -0.10973585882969494,\n",
       " -0.011759125082057037,\n",
       " -0.009305138166441518,\n",
       " 0.17406659440884104,\n",
       " 0.15963860896035795,\n",
       " 0.09943376302939758,\n",
       " 0.06081097069357906,\n",
       " 0.11055400771729504,\n",
       " -0.14948257618726418,\n",
       " -0.09294841671024007,\n",
       " -0.03949316107084733,\n",
       " -0.03271778495433025,\n",
       " -0.1206625657435978,\n",
       " 0.20895894102432747,\n",
       " -0.11717290320246554,\n",
       " -0.08666727868506552,\n",
       " -0.07395723869337525,\n",
       " 0.1220079105788417,\n",
       " -0.5890122914369856,\n",
       " -0.12819842923505984,\n",
       " -0.12255445224781125,\n",
       " -0.11775275659590773,\n",
       " -0.12069637035139205,\n",
       " 0.18972902553031765,\n",
       " 0.0784664511191583,\n",
       " -0.14763115297703122,\n",
       " 0.0182395651410336,\n",
       " -0.106798842944175,\n",
       " 0.039610376241848426,\n",
       " 0.19255574587314847,\n",
       " -0.10484132724554818,\n",
       " -0.06118884134219307,\n",
       " -0.09782334657603303,\n",
       " -0.04665315921529291,\n",
       " -0.04766776217238562,\n",
       " -0.06428223813515499,\n",
       " 0.09441881886769951,\n",
       " -0.11989566447375968,\n",
       " -0.008221130800201842,\n",
       " 0.07461561080705172,\n",
       " 0.10065673783740534,\n",
       " 0.022676209980667564,\n",
       " -0.0903153835911922,\n",
       " -0.07138185201497602,\n",
       " -0.09276269725258174,\n",
       " -0.033597719145473506,\n",
       " 0.03455369330370666,\n",
       " -0.13722128966509342,\n",
       " -0.10911927105808328,\n",
       " -0.06291384438306238,\n",
       " -0.0479209751572713,\n",
       " -0.1845114967681332,\n",
       " -0.03371901200488578,\n",
       " -0.5890122914369856,\n",
       " -0.11823574002817352,\n",
       " -0.06536817607706683,\n",
       " 0.08390388152803782,\n",
       " 0.07336754908699465,\n",
       " -0.13191808378019113,\n",
       " -0.0034074351848619455,\n",
       " -0.18431985050892383,\n",
       " 0.10225809750405934,\n",
       " -0.08402759204390545,\n",
       " 0.1920797763383415,\n",
       " -0.17245229561342917,\n",
       " 0.02322309985260318,\n",
       " 0.00351975206445114,\n",
       " -0.5890122914369856,\n",
       " -0.01697354288495409,\n",
       " 0.0490194609535575,\n",
       " 0.04126403450288072,\n",
       " 0.05663683346186432,\n",
       " 0.08794694981896933,\n",
       " 0.22846378510663895,\n",
       " -0.15264706626366523,\n",
       " 0.09480623356177506,\n",
       " -0.5890122914369856,\n",
       " -0.008622880570306496,\n",
       " -0.096401734138723,\n",
       " 0.2033417514245606,\n",
       " -0.18153520466540266,\n",
       " -0.07098366435952982,\n",
       " 0.1235435082467371,\n",
       " 0.16113522036790967,\n",
       " -0.5890122914369856,\n",
       " -0.008859370603347572,\n",
       " -0.14039912827900541,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.4619], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0434], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7743], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7688], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0682], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4923], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6125], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.4107], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0713], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5623], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5567], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0236], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2177], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0850], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4116], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7378], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5760], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1271], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5623], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2498], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5344], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0348], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9752], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8985], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0057], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4756], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.5625], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5370], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6486], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4116], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9027], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4365], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7757], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0657], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4898], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0155], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0794], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.1217], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8439], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6181], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8022], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6125], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0292], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2412], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2052], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5232], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2163], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1996], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0880], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4856], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9220], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0348], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3893], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4730], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8022], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8525], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6293], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7185], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4842], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7534], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0571], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5704], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2970], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4365], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0545], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0726], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0713], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2412], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9499], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1731], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7032], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0671], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1452], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8271], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0043], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0266], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1966], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5121], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6318], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4898], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8662], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2010], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.1831], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4786], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2219], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5816], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1017], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1966], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7074], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0545], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3684], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0824], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0348], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1798], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7743], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9052], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7602], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0099], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1215], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6851], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2442], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0838], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6795], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.0256], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.8806], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8525], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2289], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0001], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2666], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7185], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5258], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7353], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1047], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7967], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1494], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1438], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4340], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7409], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2610], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2498], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0961], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.8303], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9834], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0113], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4172], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4116], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.3828], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2914], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.7076], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7688], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7409], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0322], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1508], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4340], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7434], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4756], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0266], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7799], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2524], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4507], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0459], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6572], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8104], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0236], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4842], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9138], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8594], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5425], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5649], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2356], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4953], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.2935], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0322], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1842], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7018], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6348], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0292], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4086], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5704], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7018], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3975], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6181], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9164], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2163], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6597], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9696], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6181], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0378], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6765], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8036], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0824], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7520], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1382], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6683], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6125], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5958], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8160], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9220], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.9264], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4744], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7936], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.4776], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.3270], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3249], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3070], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3782], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6962], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4451], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1508], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4619], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9108], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5146], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5288], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7130], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([4.2253], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8022], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5567], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7855], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9052], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1494], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6293], device='cuda:0', dtype=torch.float64),\n",
       " tensor([4.9117], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7799], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4619], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5902], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0043], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9722], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1352], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.0547], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1619], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7520], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7409], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0434], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.9487], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9138], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3305], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7881], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3070], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3279], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2610], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5816], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9473], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1829], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5790], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7323], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6572], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.9431], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3249], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3558], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0824], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1798], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8048], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1240], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4786], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7241], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4228], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7018], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2610], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7353], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2524], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2610], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.2433], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1829], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0099], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0434], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7241], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8078], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5177], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4588], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9027], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2442], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3138], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4644], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([4.2030], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2747], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8439], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2568], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1215], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6851], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9220], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8748], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6739], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0224], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6683], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5902], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5916], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0880], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7602], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0224], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7688], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4030], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3000], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2468], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5177], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4911], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6739], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5916], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.0380], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9945], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7185], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6851], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4421], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3056], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1494], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0545], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1438], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3349], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0515], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5928], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4533], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.8850], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.5458], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4800], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4979], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8190], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1773], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8022], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7155], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2791], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9108], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0403], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0782], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4674], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4198], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4786], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3807], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1073], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0545], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5983], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7241], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4353], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3640], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9610], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.5904], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7241], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0671], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7799], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1966], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3975], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7657], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5511], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2077], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7520], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9529], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6962], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8915], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6460], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1996], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4800], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8748], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7743], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9778], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1605], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6906], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6572], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.0715], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1215], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4228], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4451], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4086], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7074], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7353], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2245], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.1831], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6014], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8817], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7743], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5537], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3249], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1996], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3472], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0266], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8941], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0627], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8078], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4923], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3305], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0515], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3014], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6293], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7255], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5928], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6095], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2524], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7323], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3696], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9138], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5735], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7520], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2052], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2721], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3405], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3949], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3349], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.1552], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6683], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.0938], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.9419], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4030], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3751], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7799], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7367], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5790], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4533], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6739], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0180], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3893], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0378], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2554], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4451], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5760], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9529], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8525], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8706], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8662], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5623], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.5904], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6795], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6486], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3026], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7409], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1438], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2442], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8190], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.0324], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3361], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.4342], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4507], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8383], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3361], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7199], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8078], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1382], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.3616], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9696], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5511], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7713], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2442], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5035], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.3616], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8748], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0043], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.5725], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6795], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7311], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2010], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7434], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5916], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7799], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7911], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5790], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5358], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3447], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5288], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4786], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3628], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9138], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0489], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5190], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.2668], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4451], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6151], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3391], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0627], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6653], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4842], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2219], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6181], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.1552], device='cuda:0', dtype=torch.float64),\n",
       " tensor([4.8782], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9722], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0322], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9220], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2189], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8873], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4298], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0961], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4477], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7018], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6683], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4619], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7769], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7130], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5344], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0113], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5649], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7185], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1550], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7688], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1910], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7576], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0601], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5902], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6516], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4172], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1605], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5232], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5146], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1159], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7855], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0236], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4856], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1717], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2721], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.6295], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2052], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6530], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1215], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8160], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6181], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.5625], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8190], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5400], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6920], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1661], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8469], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0489], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1408], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7576], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1884], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1966], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5177], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3558], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7297], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8525], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7297], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6237], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5314], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9834], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.5290], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0545], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3026], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2524], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1829], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9473], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7434], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9529], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.8483], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3070], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.8638], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1743], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6039], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6460], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5232], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7881], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7855], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1438], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9027], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6293], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9138], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5902], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6820], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1047], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6293], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4923], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1073], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.4174], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6962], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3528], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3807], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5846], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4953], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9752], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6627], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7602], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7911], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2554], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9027], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9473], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7799], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8078], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1103], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2412], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2970], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2412], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4953], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2331], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9473], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6516], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4340], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6683], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4340], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4228], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4619], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.4955], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3335], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8718], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3026], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.2221], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0906], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4756], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9362], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2691], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5637], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4812], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0950], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4353], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8271], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0001], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2610], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4867], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4744], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4856], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1631], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7713], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2077], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4563], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.8415], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7855], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3807], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8190], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.3851], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7520], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0992], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0627], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5735], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4507], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1798], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8997], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5958], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7353], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.1149], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1966], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0782], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8525], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6237], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1854], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6430], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2666], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4700], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6125], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.5023], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4142], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2077], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4172], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7632], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6237], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4812], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8748], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2914], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1494], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5121], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0292], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6404], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6069], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3026], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2442], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0057], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6262], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5537], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9083], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3614], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8078], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8357], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7143], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2498], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1017], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.1831], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7855], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2524], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3335], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4284], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6572], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8078], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6293], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8022], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8190], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8804], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2456], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9250], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9194], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5679], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7267], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0447], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9473], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4395], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9027], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9473], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8246], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.1229], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.2847], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9027], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6474], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9276], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2666], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5121], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4786], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8413], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5623], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.6016], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1408], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4451], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1129], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6374], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.2219], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8692], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6348], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5288], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0043], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6851], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.0961], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.7590], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4074], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6962], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6139], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9276], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1271], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2412], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5983], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.7044], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8606], device='cuda:0', dtype=torch.float64),\n",
       " tensor([4.0747], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8636], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4086], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.4744], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1884], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8580], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.5735], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.9264], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8829], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6795], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.8941], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.9889], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.5370], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0210], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.3058], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8134], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7520], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0322], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6683], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0782], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6486], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9529], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9417], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8859], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3391], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6348], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.4063], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4730], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.6876], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.0894], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.3782], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.9585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7576], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7464], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.4172], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.3305], device='cuda:0', dtype=torch.float64),\n",
       " tensor([2.8415], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.1605], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0378], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.0880], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.9654], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.2022], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6585], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8301], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.6851], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.1296], device='cuda:0', dtype=torch.float64),\n",
       " tensor([1.6306], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.8971], device='cuda:0', dtype=torch.float64),\n",
       " tensor([0.4421], device='cuda:0', dtype=torch.float64),\n",
       " tensor([-0.7241], device='cuda:0', dtype=torch.float64),\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = price_scaler.inverse_transform(np.array(y_pred_scaled).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mdae = median_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "#mdape = ((pd.Series(y_test) - pd.Series(y_pred))\\\n",
    "        # / pd.Series(y_test)).abs().median()\n",
    "r_squared = r2_score(y_test, y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7280485022849993,\n",
       " 0.6463390034491812,\n",
       " 0.9119851236004479,\n",
       " 1.0946573377981599,\n",
       " 0.08801487639955208)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mae, mdae, mse, mape, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def evaluate():\n",
    "        test_dataloader2 = create_dataloaders(test_inputs, test_masks, \n",
    "                                test_labels, 1)\n",
    "        y_pred_scaled2, labels2 = predict(model, test_dataloader2, device)\n",
    "        y_test2= list(map(lambda x : x.to(\"cpu\").numpy()[0], labels2))\n",
    "        y_pred2= list(map(lambda x : x.to(\"cpu\").numpy()[0], y_pred_scaled2))\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        from sklearn.metrics import median_absolute_error\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.metrics import mean_absolute_percentage_error\n",
    "        from sklearn.metrics import r2_score\n",
    "        mae = mean_absolute_error(y_test2, y_pred2)\n",
    "        mdae = median_absolute_error(y_test2, y_pred2)\n",
    "        mse = mean_squared_error(y_test2, y_pred2)\n",
    "        mape = mean_absolute_percentage_error(y_test2, y_pred2)\n",
    "        #mdape = ((pd.Series(y_test) - pd.Series(y_pred))\\\n",
    "                # / pd.Series(y_test)).abs().median()\n",
    "        r_squared = r2_score(y_test2, y_pred2)\n",
    "        print(mae, mdae, mse, mape, r_squared)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "mae = mean_absolute_error(y_test2, y_pred2)\n",
    "mdae = median_absolute_error(y_test2, y_pred2)\n",
    "mse = mean_squared_error(y_test2, y_pred2)\n",
    "mape = mean_absolute_percentage_error(y_test2, y_pred2)\n",
    "#mdape = ((pd.Series(y_test) - pd.Series(y_pred))\\\n",
    "        # / pd.Series(y_test)).abs().median()\n",
    "r_squared = r2_score(y_test2, y_pred2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7338061747313142,\n",
       " 0.6844490938418113,\n",
       " 0.8452176128890638,\n",
       " 1.1206721551252143,\n",
       " 0.019483549335861827)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mae, mdae, mse, mape, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,\"trained_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenvn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
